---
# Source: blinkchamber/charts/vault/templates/server-disruptionbudget.yaml
# PodDisruptionBudget to prevent degrading the server cluster through
# voluntary cluster changes.
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: blinkchamber-vault
  namespace: blinkchamber
  labels:
    helm.sh/chart: vault-0.27.0
    app.kubernetes.io/name: vault
    app.kubernetes.io/instance: blinkchamber
    app.kubernetes.io/managed-by: Helm
spec:
  maxUnavailable: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: vault
      app.kubernetes.io/instance: blinkchamber
      component: server
---
# Source: blinkchamber/charts/postgresql/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: blinkchamber-postgresql
  namespace: "blinkchamber"
  labels:
    app.kubernetes.io/instance: blinkchamber
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/version: 16.1.0
    helm.sh/chart: postgresql-13.2.30
automountServiceAccountToken: false
---
# Source: blinkchamber/charts/vault/templates/injector-serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: blinkchamber-vault-agent-injector
  namespace: blinkchamber
  labels:
    app.kubernetes.io/name: vault-agent-injector
    app.kubernetes.io/instance: blinkchamber
    app.kubernetes.io/managed-by: Helm
---
# Source: blinkchamber/charts/vault/templates/server-serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: blinkchamber-vault
  namespace: blinkchamber
  labels:
    helm.sh/chart: vault-0.27.0
    app.kubernetes.io/name: vault
    app.kubernetes.io/instance: blinkchamber
    app.kubernetes.io/managed-by: Helm
---
# Source: blinkchamber/templates/grafana-deployment.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: blinkchamber-grafana-sa
  namespace: blinkchamber
  labels:
    helm.sh/chart: blinkchamber-0.1.0
    app.kubernetes.io/name: blinkchamber
    app.kubernetes.io/instance: blinkchamber
    app.kubernetes.io/version: "1.0.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: grafana
---
# Source: blinkchamber/templates/mailu-deployment.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: blinkchamber-mailu-sa
  namespace: blinkchamber
  labels:
    helm.sh/chart: blinkchamber-0.1.0
    app.kubernetes.io/name: blinkchamber
    app.kubernetes.io/instance: blinkchamber
    app.kubernetes.io/version: "1.0.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: mailu
---
# Source: blinkchamber/templates/prometheus-deployment.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: blinkchamber-prometheus-sa
  namespace: blinkchamber
  labels:
    helm.sh/chart: blinkchamber-0.1.0
    app.kubernetes.io/name: blinkchamber
    app.kubernetes.io/instance: blinkchamber
    app.kubernetes.io/version: "1.0.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: prometheus
---
# Source: blinkchamber/templates/vault-init-job.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: blinkchamber-vault-init
  namespace: blinkchamber
  labels:
    helm.sh/chart: blinkchamber-0.1.0
    app.kubernetes.io/name: blinkchamber
    app.kubernetes.io/instance: blinkchamber
    app.kubernetes.io/version: "1.0.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: vault-init
---
# Source: blinkchamber/templates/zitadel-deployment.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: blinkchamber-zitadel-sa
  namespace: blinkchamber
  labels:
    helm.sh/chart: blinkchamber-0.1.0
    app.kubernetes.io/name: blinkchamber
    app.kubernetes.io/instance: blinkchamber
    app.kubernetes.io/version: "1.0.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: zitadel
---
# Source: blinkchamber/charts/postgresql/templates/secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: blinkchamber-postgresql
  namespace: "blinkchamber"
  labels:
    app.kubernetes.io/instance: blinkchamber
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/version: 16.1.0
    helm.sh/chart: postgresql-13.2.30
type: Opaque
data:
  postgres-password: "cG9zdGdyZXMxMjM="
  # We don't auto-generate LDAP password when it's not provided as we do for other passwords
---
# Source: blinkchamber/charts/vault/templates/server-config-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: blinkchamber-vault-config
  namespace: blinkchamber
  labels:
    helm.sh/chart: vault-0.27.0
    app.kubernetes.io/name: vault
    app.kubernetes.io/instance: blinkchamber
    app.kubernetes.io/managed-by: Helm
data:
  extraconfig-from-values.hcl: |-
    disable_mlock = true
    ui = true
    
    listener "tcp" {
      tls_disable = 1
      address = "[::]:8200"
      cluster_address = "[::]:8201"
    }
    storage "consul" {
      path = "vault"
      address = "HOST_IP:8500"
    }
    
    service_registration "kubernetes" {}
    
    # Example configuration for using auto-unseal, using Google Cloud KMS. The
    # GKMS keys must already exist, and the cluster must have a service account
    # that is authorized to access GCP KMS.
    #seal "gcpckms" {
    #   project     = "vault-helm-dev-246514"
    #   region      = "global"
    #   key_ring    = "vault-helm-unseal-kr"
    #   crypto_key  = "vault-helm-unseal-key"
    #}
    
    # Example configuration for enabling Prometheus metrics.
    # If you are using Prometheus Operator you can enable a ServiceMonitor resource below.
    # You may wish to enable unauthenticated metrics in the listener block above.
    #telemetry {
    #  prometheus_retention_time = "30s"
    #  disable_hostname = true
    #}
---
# Source: blinkchamber/templates/grafana-deployment.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: blinkchamber-grafana-vault-agent-config
  namespace: blinkchamber
  labels:
    helm.sh/chart: blinkchamber-0.1.0
    app.kubernetes.io/name: blinkchamber
    app.kubernetes.io/instance: blinkchamber
    app.kubernetes.io/version: "1.0.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: grafana
data:
  agent-config.hcl: |
    exit_after_auth = false
    pid_file = "/tmp/vault-agent-pid"
    auto_auth {
      method "kubernetes" {
        mount_path = "auth/kubernetes"
        config = {
          role = "grafana-role"
        }
      }
      sink "file" {
        config = {
          path = "/vault/secrets/vault-token"
        }
      }
    }
    template {
      source      = "/vault/config/grafana-admin.tpl"
      destination = "/vault/secrets/grafana_admin_password"
    }
    vault {
      address = "http://blinkchamber-vault:8200"
    }
  grafana-admin.tpl: |
    {{ with secret "secret/monitoring/grafana" }}
    {{ .Data.data.admin_password }}
    {{ end }}
---
# Source: blinkchamber/templates/mailu-deployment.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: blinkchamber-mailu-config
  namespace: blinkchamber
  labels:
    helm.sh/chart: blinkchamber-0.1.0
    app.kubernetes.io/name: blinkchamber
    app.kubernetes.io/instance: blinkchamber
    app.kubernetes.io/version: "1.0.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: mailu
data:
  mailu.yml: |
    # Mailu configuration
    hostname: mail.blinkchamber.local
    secret_key: ""

    # Database configuration
    database:
      engine: postgresql
      host: blinkchamber-postgresql
      port: 5432
      name: mailu
      user: mailu
      password: ""

    # Web configuration
    web:
      host: 0.0.0.0
      port: 80
      ssl_port: 443

    # Mail configuration
    mail:
      smtp:
        host: 0.0.0.0
        port: 25
        ssl_port: 587
      imap:
        host: 0.0.0.0
        port: 143
        ssl_port: 993
      pop3:
        host: 0.0.0.0
        port: 110
        ssl_port: 995

    # Storage configuration
    storage:
      path: /data
---
# Source: blinkchamber/templates/mailu-deployment.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: blinkchamber-mailu-vault-agent-config
  namespace: blinkchamber
  labels:
    helm.sh/chart: blinkchamber-0.1.0
    app.kubernetes.io/name: blinkchamber
    app.kubernetes.io/instance: blinkchamber
    app.kubernetes.io/version: "1.0.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: mailu
data:
  agent-config.hcl: |
    exit_after_auth = false
    pid_file = "/tmp/vault-agent-pid"
    auto_auth {
      method "kubernetes" {
        mount_path = "auth/kubernetes"
        config = {
          role = "mailu-role"
        }
      }
      sink "file" {
        config = {
          path = "/vault/secrets/vault-token"
        }
      }
    }
    template {
      source      = "/vault/config/mailu-secret.tpl"
      destination = "/vault/secrets/mailu_secret_key"
    }
    template {
      source      = "/vault/config/mailu-admin.tpl"
      destination = "/vault/secrets/mailu_admin_password"
    }
    template {
      source      = "/vault/config/mailu-db.tpl"
      destination = "/vault/secrets/mailu_db_password"
    }
    vault {
      address = "http://blinkchamber-vault:8200"
    }
  mailu-secret.tpl: |
    {{ with secret "secret/mail/mailu" }}
    {{ .Data.data.secret_key }}
    {{ end }}
  mailu-admin.tpl: |
    {{ with secret "secret/mail/mailu" }}
    {{ .Data.data.admin_password }}
    {{ end }}
  mailu-db.tpl: |
    {{ with secret "secret/mail/mailu" }}
    {{ .Data.data.database_password }}
    {{ end }}
---
# Source: blinkchamber/templates/prometheus-deployment.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: blinkchamber-prometheus-config
  namespace: blinkchamber
  labels:
    helm.sh/chart: blinkchamber-0.1.0
    app.kubernetes.io/name: blinkchamber
    app.kubernetes.io/instance: blinkchamber
    app.kubernetes.io/version: "1.0.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: prometheus
data:
  prometheus.yml: |
    global:
      scrape_interval: 15s
      evaluation_interval: 15s

    rule_files:
      # - "first_rules.yml"
      # - "second_rules.yml"

    scrape_configs:
      - job_name: 'prometheus'
        static_configs:
          - targets: ['localhost:9090']

      - job_name: 'kubernetes-pods'
        kubernetes_sd_configs:
          - role: pod
        relabel_configs:
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
            action: keep
            regex: true
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
            action: replace
            target_label: __metrics_path__
            regex: (.+)
          - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
            action: replace
            regex: ([^:]+)(?::\d+)?;(\d+)
            replacement: $1:$2
            target_label: __address__
          - action: labelmap
            regex: __meta_kubernetes_pod_label_(.+)
          - source_labels: [__meta_kubernetes_namespace]
            action: replace
            target_label: kubernetes_namespace
          - source_labels: [__meta_kubernetes_pod_name]
            action: replace
            target_label: kubernetes_pod_name
---
# Source: blinkchamber/templates/prometheus-deployment.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: blinkchamber-prometheus-vault-agent-config
  namespace: blinkchamber
  labels:
    helm.sh/chart: blinkchamber-0.1.0
    app.kubernetes.io/name: blinkchamber
    app.kubernetes.io/instance: blinkchamber
    app.kubernetes.io/version: "1.0.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: prometheus
data:
  agent-config.hcl: |
    exit_after_auth = false
    pid_file = "/tmp/vault-agent-pid"

    auto_auth {
      method "kubernetes" {
        mount_path = "auth/kubernetes"
        config = {
          role = "prometheus-role"
        }
      }
      sink "file" {
        config = {
          path = "/vault/secrets/vault-token"
        }
      }
    }

    template {
      source      = "/vault/config/prometheus-admin.tpl"
      destination = "/vault/secrets/prometheus_admin_password"
    }

    vault {
      address = "http://blinkchamber-vault:8200"
    }

  prometheus-admin.tpl: |
    {{ with secret "secret/monitoring/prometheus" }}
    {{ .Data.data.admin_password }}
    {{ end }}
---
# Source: blinkchamber/templates/zitadel-deployment.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: blinkchamber-zitadel-vault-agent-config
  namespace: blinkchamber
  labels:
    helm.sh/chart: blinkchamber-0.1.0
    app.kubernetes.io/name: blinkchamber
    app.kubernetes.io/instance: blinkchamber
    app.kubernetes.io/version: "1.0.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: zitadel
data:
  agent-config.hcl: |
    exit_after_auth = false
    pid_file = "/tmp/vault-agent-pid"

    auto_auth {
      method "kubernetes" {
        mount_path = "auth/kubernetes"
        config = {
          role = "zitadel-role"
        }
      }
      sink "file" {
        config = {
          path = "/vault/secrets/vault-token"
        }
      }
    }

    template {
      source      = "/vault/config/zitadel-masterkey.tpl"
      destination = "/vault/secrets/zitadel_masterkey"
    }

    template {
      source      = "/vault/config/zitadel-admin.tpl"
      destination = "/vault/secrets/zitadel_admin_username"
    }

    template {
      source      = "/vault/config/zitadel-admin-password.tpl"
      destination = "/vault/secrets/zitadel_admin_password"
    }

    template {
      source      = "/vault/config/postgres-username.tpl"
      destination = "/vault/secrets/postgres_username"
    }

    template {
      source      = "/vault/config/postgres-password.tpl"
      destination = "/vault/secrets/postgres_password"
    }

    vault {
      address = "http://blinkchamber-vault:8200"
    }

  zitadel-masterkey.tpl: |
    {{ with secret "secret/identity/zitadel" }}
    {{ .Data.data.masterkey }}
    {{ end }}

  zitadel-admin.tpl: |
    {{ with secret "secret/identity/zitadel" }}
    {{ .Data.data.admin_username }}
    {{ end }}

  zitadel-admin-password.tpl: |
    {{ with secret "secret/identity/zitadel" }}
    {{ .Data.data.admin_password }}
    {{ end }}

  postgres-username.tpl: |
    {{ with secret "secret/database/postgres" }}
    {{ .Data.data.username }}
    {{ end }}

  postgres-password.tpl: |
    {{ with secret "secret/database/postgres" }}
    {{ .Data.data.password }}
    {{ end }}
---
# Source: blinkchamber/templates/grafana-deployment.yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: blinkchamber-grafana-pvc
  namespace: blinkchamber
  labels:
    helm.sh/chart: blinkchamber-0.1.0
    app.kubernetes.io/name: blinkchamber
    app.kubernetes.io/instance: blinkchamber
    app.kubernetes.io/version: "1.0.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: grafana
spec:
  accessModes:
    - ReadWriteOnce
  storageClassName: standard
  resources:
    requests:
      storage: 5Gi
---
# Source: blinkchamber/templates/mailu-deployment.yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: blinkchamber-mailu-pvc
  namespace: blinkchamber
  labels:
    helm.sh/chart: blinkchamber-0.1.0
    app.kubernetes.io/name: blinkchamber
    app.kubernetes.io/instance: blinkchamber
    app.kubernetes.io/version: "1.0.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: mailu
spec:
  accessModes:
    - ReadWriteOnce
  storageClassName: standard
  resources:
    requests:
      storage: 10Gi
---
# Source: blinkchamber/templates/prometheus-deployment.yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: blinkchamber-prometheus-pvc
  namespace: blinkchamber
  labels:
    helm.sh/chart: blinkchamber-0.1.0
    app.kubernetes.io/name: blinkchamber
    app.kubernetes.io/instance: blinkchamber
    app.kubernetes.io/version: "1.0.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: prometheus
spec:
  accessModes:
    - ReadWriteOnce
  storageClassName: standard
  resources:
    requests:
      storage: 8Gi
---
# Source: blinkchamber/charts/vault/templates/injector-clusterrole.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: blinkchamber-vault-agent-injector-clusterrole
  labels:
    app.kubernetes.io/name: vault-agent-injector
    app.kubernetes.io/instance: blinkchamber
    app.kubernetes.io/managed-by: Helm
rules:
- apiGroups: ["admissionregistration.k8s.io"]
  resources: ["mutatingwebhookconfigurations"]
  verbs:
    - "get"
    - "list"
    - "watch"
    - "patch"
---
# Source: blinkchamber/charts/vault/templates/injector-clusterrolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: blinkchamber-vault-agent-injector-binding
  labels:
    app.kubernetes.io/name: vault-agent-injector
    app.kubernetes.io/instance: blinkchamber
    app.kubernetes.io/managed-by: Helm
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: blinkchamber-vault-agent-injector-clusterrole
subjects:
- kind: ServiceAccount
  name: blinkchamber-vault-agent-injector
  namespace: blinkchamber
---
# Source: blinkchamber/charts/vault/templates/server-clusterrolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: blinkchamber-vault-server-binding
  labels:
    helm.sh/chart: vault-0.27.0
    app.kubernetes.io/name: vault
    app.kubernetes.io/instance: blinkchamber
    app.kubernetes.io/managed-by: Helm
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: system:auth-delegator
subjects:
- kind: ServiceAccount
  name: blinkchamber-vault
  namespace: blinkchamber
---
# Source: blinkchamber/charts/vault/templates/server-discovery-role.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  namespace: blinkchamber
  name: blinkchamber-vault-discovery-role
  labels:
    helm.sh/chart: vault-0.27.0
    app.kubernetes.io/name: vault
    app.kubernetes.io/instance: blinkchamber
    app.kubernetes.io/managed-by: Helm
rules:
- apiGroups: [""]
  resources: ["pods"]
  verbs: ["get", "watch", "list", "update", "patch"]
---
# Source: blinkchamber/templates/grafana-deployment.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: blinkchamber-grafana-role
  namespace: blinkchamber
  labels:
    helm.sh/chart: blinkchamber-0.1.0
    app.kubernetes.io/name: blinkchamber
    app.kubernetes.io/instance: blinkchamber
    app.kubernetes.io/version: "1.0.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: grafana
rules:
  - apiGroups: [""]
    resources: ["secrets"]
    verbs: ["get", "list"]
---
# Source: blinkchamber/templates/mailu-deployment.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: blinkchamber-mailu-role
  namespace: blinkchamber
  labels:
    helm.sh/chart: blinkchamber-0.1.0
    app.kubernetes.io/name: blinkchamber
    app.kubernetes.io/instance: blinkchamber
    app.kubernetes.io/version: "1.0.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: mailu
rules:
  - apiGroups: [""]
    resources: ["secrets"]
    verbs: ["get", "list"]
---
# Source: blinkchamber/templates/prometheus-deployment.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: blinkchamber-prometheus-role
  namespace: blinkchamber
  labels:
    helm.sh/chart: blinkchamber-0.1.0
    app.kubernetes.io/name: blinkchamber
    app.kubernetes.io/instance: blinkchamber
    app.kubernetes.io/version: "1.0.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: prometheus
rules:
  - apiGroups: [""]
    resources: ["secrets"]
    verbs: ["get", "list"]
---
# Source: blinkchamber/templates/vault-init-job.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: blinkchamber-vault-init
  namespace: blinkchamber
  labels:
    helm.sh/chart: blinkchamber-0.1.0
    app.kubernetes.io/name: blinkchamber
    app.kubernetes.io/instance: blinkchamber
    app.kubernetes.io/version: "1.0.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: vault-init
rules:
  - apiGroups: [""]
    resources: ["pods", "secrets"]
    verbs: ["get", "list", "create", "update", "patch"]
  - apiGroups: [""]
    resources: ["pods/exec"]
    verbs: ["create"]
---
# Source: blinkchamber/templates/zitadel-deployment.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: blinkchamber-zitadel-role
  namespace: blinkchamber
  labels:
    helm.sh/chart: blinkchamber-0.1.0
    app.kubernetes.io/name: blinkchamber
    app.kubernetes.io/instance: blinkchamber
    app.kubernetes.io/version: "1.0.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: zitadel
rules:
  - apiGroups: [""]
    resources: ["secrets"]
    verbs: ["get", "list"]
---
# Source: blinkchamber/charts/vault/templates/server-discovery-rolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: blinkchamber-vault-discovery-rolebinding
  namespace: blinkchamber
  labels:
    helm.sh/chart: vault-0.27.0
    app.kubernetes.io/name: vault
    app.kubernetes.io/instance: blinkchamber
    app.kubernetes.io/managed-by: Helm
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: blinkchamber-vault-discovery-role
subjects:
- kind: ServiceAccount
  name: blinkchamber-vault
  namespace: blinkchamber
---
# Source: blinkchamber/templates/grafana-deployment.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: blinkchamber-grafana-rolebinding
  namespace: blinkchamber
  labels:
    helm.sh/chart: blinkchamber-0.1.0
    app.kubernetes.io/name: blinkchamber
    app.kubernetes.io/instance: blinkchamber
    app.kubernetes.io/version: "1.0.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: grafana
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: blinkchamber-grafana-role
subjects:
- kind: ServiceAccount
  name: blinkchamber-grafana-sa
  namespace: blinkchamber
---
# Source: blinkchamber/templates/mailu-deployment.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: blinkchamber-mailu-rolebinding
  namespace: blinkchamber
  labels:
    helm.sh/chart: blinkchamber-0.1.0
    app.kubernetes.io/name: blinkchamber
    app.kubernetes.io/instance: blinkchamber
    app.kubernetes.io/version: "1.0.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: mailu
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: blinkchamber-mailu-role
subjects:
- kind: ServiceAccount
  name: blinkchamber-mailu-sa
  namespace: blinkchamber
---
# Source: blinkchamber/templates/prometheus-deployment.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: blinkchamber-prometheus-rolebinding
  namespace: blinkchamber
  labels:
    helm.sh/chart: blinkchamber-0.1.0
    app.kubernetes.io/name: blinkchamber
    app.kubernetes.io/instance: blinkchamber
    app.kubernetes.io/version: "1.0.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: prometheus
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: blinkchamber-prometheus-role
subjects:
- kind: ServiceAccount
  name: blinkchamber-prometheus-sa
  namespace: blinkchamber
---
# Source: blinkchamber/templates/vault-init-job.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: blinkchamber-vault-init
  namespace: blinkchamber
  labels:
    helm.sh/chart: blinkchamber-0.1.0
    app.kubernetes.io/name: blinkchamber
    app.kubernetes.io/instance: blinkchamber
    app.kubernetes.io/version: "1.0.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: vault-init
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: blinkchamber-vault-init
subjects:
- kind: ServiceAccount
  name: blinkchamber-vault-init
  namespace: blinkchamber
---
# Source: blinkchamber/templates/zitadel-deployment.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: blinkchamber-zitadel-rolebinding
  namespace: blinkchamber
  labels:
    helm.sh/chart: blinkchamber-0.1.0
    app.kubernetes.io/name: blinkchamber
    app.kubernetes.io/instance: blinkchamber
    app.kubernetes.io/version: "1.0.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: zitadel
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: blinkchamber-zitadel-role
subjects:
- kind: ServiceAccount
  name: blinkchamber-zitadel-sa
  namespace: blinkchamber
---
# Source: blinkchamber/charts/postgresql/templates/primary/svc-headless.yaml
apiVersion: v1
kind: Service
metadata:
  name: blinkchamber-postgresql-hl
  namespace: "blinkchamber"
  labels:
    app.kubernetes.io/instance: blinkchamber
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/version: 16.1.0
    helm.sh/chart: postgresql-13.2.30
    app.kubernetes.io/component: primary
  annotations:
    # Use this annotation in addition to the actual publishNotReadyAddresses
    # field below because the annotation will stop being respected soon but the
    # field is broken in some versions of Kubernetes:
    # https://github.com/kubernetes/kubernetes/issues/58662
    service.alpha.kubernetes.io/tolerate-unready-endpoints: "true"
spec:
  type: ClusterIP
  clusterIP: None
  # We want all pods in the StatefulSet to have their addresses published for
  # the sake of the other Postgresql pods even before they're ready, since they
  # have to be able to talk to each other in order to become ready.
  publishNotReadyAddresses: true
  ports:
    - name: tcp-postgresql
      port: 5432
      targetPort: tcp-postgresql
  selector:
    app.kubernetes.io/instance: blinkchamber
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/component: primary
---
# Source: blinkchamber/charts/postgresql/templates/primary/svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: blinkchamber-postgresql
  namespace: "blinkchamber"
  labels:
    app.kubernetes.io/instance: blinkchamber
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/version: 16.1.0
    helm.sh/chart: postgresql-13.2.30
    app.kubernetes.io/component: primary
spec:
  type: ClusterIP
  sessionAffinity: None
  ports:
    - name: tcp-postgresql
      port: 5432
      targetPort: tcp-postgresql
      nodePort: null
  selector:
    app.kubernetes.io/instance: blinkchamber
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/component: primary
---
# Source: blinkchamber/charts/vault/templates/injector-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: blinkchamber-vault-agent-injector-svc
  namespace: blinkchamber
  labels:
    app.kubernetes.io/name: vault-agent-injector
    app.kubernetes.io/instance: blinkchamber
    app.kubernetes.io/managed-by: Helm
  
spec:
  ports:
  - name: https
    port: 443
    targetPort: 8080
  selector:
    app.kubernetes.io/name: vault-agent-injector
    app.kubernetes.io/instance: blinkchamber
    component: webhook
---
# Source: blinkchamber/charts/vault/templates/server-ha-active-service.yaml
# Service for active Vault pod
apiVersion: v1
kind: Service
metadata:
  name: blinkchamber-vault-active
  namespace: blinkchamber
  labels:
    helm.sh/chart: vault-0.27.0
    app.kubernetes.io/name: vault
    app.kubernetes.io/instance: blinkchamber
    app.kubernetes.io/managed-by: Helm
    vault-active: "true"
  annotations:
spec:
  publishNotReadyAddresses: true
  ports:
    - name: http
      port: 8200
      targetPort: 8200
    - name: https-internal
      port: 8201
      targetPort: 8201
  selector:
    app.kubernetes.io/name: vault
    app.kubernetes.io/instance: blinkchamber
    component: server
    vault-active: "true"
---
# Source: blinkchamber/charts/vault/templates/server-ha-standby-service.yaml
# Service for standby Vault pod
apiVersion: v1
kind: Service
metadata:
  name: blinkchamber-vault-standby
  namespace: blinkchamber
  labels:
    helm.sh/chart: vault-0.27.0
    app.kubernetes.io/name: vault
    app.kubernetes.io/instance: blinkchamber
    app.kubernetes.io/managed-by: Helm
  annotations:
spec:
  publishNotReadyAddresses: true
  ports:
    - name: http
      port: 8200
      targetPort: 8200
    - name: https-internal
      port: 8201
      targetPort: 8201
  selector:
    app.kubernetes.io/name: vault
    app.kubernetes.io/instance: blinkchamber
    component: server
    vault-active: "false"
---
# Source: blinkchamber/charts/vault/templates/server-headless-service.yaml
# Service for Vault cluster
apiVersion: v1
kind: Service
metadata:
  name: blinkchamber-vault-internal
  namespace: blinkchamber
  labels:
    helm.sh/chart: vault-0.27.0
    app.kubernetes.io/name: vault
    app.kubernetes.io/instance: blinkchamber
    app.kubernetes.io/managed-by: Helm
    vault-internal: "true"
  annotations:

spec:
  clusterIP: None
  publishNotReadyAddresses: true
  ports:
    - name: "http"
      port: 8200
      targetPort: 8200
    - name: https-internal
      port: 8201
      targetPort: 8201
  selector:
    app.kubernetes.io/name: vault
    app.kubernetes.io/instance: blinkchamber
    component: server
---
# Source: blinkchamber/charts/vault/templates/server-service.yaml
# Service for Vault cluster
apiVersion: v1
kind: Service
metadata:
  name: blinkchamber-vault
  namespace: blinkchamber
  labels:
    helm.sh/chart: vault-0.27.0
    app.kubernetes.io/name: vault
    app.kubernetes.io/instance: blinkchamber
    app.kubernetes.io/managed-by: Helm
  annotations:

spec:
  # We want the servers to become available even if they're not ready
  # since this DNS is also used for join operations.
  publishNotReadyAddresses: true
  ports:
    - name: http
      port: 8200
      targetPort: 8200
    - name: https-internal
      port: 8201
      targetPort: 8201
  selector:
    app.kubernetes.io/name: vault
    app.kubernetes.io/instance: blinkchamber
    component: server
---
# Source: blinkchamber/charts/vault/templates/ui-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: blinkchamber-vault-ui
  namespace: blinkchamber
  labels:
    helm.sh/chart: vault-0.27.0
    app.kubernetes.io/name: vault-ui
    app.kubernetes.io/instance: blinkchamber
    app.kubernetes.io/managed-by: Helm
spec:
  selector:
    app.kubernetes.io/name: vault
    app.kubernetes.io/instance: blinkchamber
    component: server
  publishNotReadyAddresses: true
  ports:
    - name: http
      port: 8200
      targetPort: 8200
  type: ClusterIP
---
# Source: blinkchamber/templates/grafana-deployment.yaml
apiVersion: v1
kind: Service
metadata:
  name: blinkchamber-grafana
  namespace: blinkchamber
  labels:
    helm.sh/chart: blinkchamber-0.1.0
    app.kubernetes.io/name: blinkchamber
    app.kubernetes.io/instance: blinkchamber
    app.kubernetes.io/version: "1.0.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: grafana
spec:
  selector:
    app.kubernetes.io/name: blinkchamber
    app.kubernetes.io/instance: blinkchamber
    app.kubernetes.io/component: grafana
  ports:
  - name: http
    port: 3000
    targetPort: 3000
  type: ClusterIP
---
# Source: blinkchamber/templates/mailu-deployment.yaml
apiVersion: v1
kind: Service
metadata:
  name: blinkchamber-mailu
  namespace: blinkchamber
  labels:
    helm.sh/chart: blinkchamber-0.1.0
    app.kubernetes.io/name: blinkchamber
    app.kubernetes.io/instance: blinkchamber
    app.kubernetes.io/version: "1.0.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: mailu
spec:
  selector:
    app.kubernetes.io/name: blinkchamber
    app.kubernetes.io/instance: blinkchamber
    app.kubernetes.io/component: mailu
  ports:
  - name: http
    port: 80
    targetPort: 80
  - name: https
    port: 443
    targetPort: 443
  - name: smtp
    port: 25
    targetPort: 25
  - name: smtps
    port: 587
    targetPort: 587
  - name: imap
    port: 143
    targetPort: 143
  - name: imaps
    port: 993
    targetPort: 993
  - name: pop3
    port: 110
    targetPort: 110
  - name: pop3s
    port: 995
    targetPort: 995
  type: ClusterIP
---
# Source: blinkchamber/templates/prometheus-deployment.yaml
apiVersion: v1
kind: Service
metadata:
  name: blinkchamber-prometheus
  namespace: blinkchamber
  labels:
    helm.sh/chart: blinkchamber-0.1.0
    app.kubernetes.io/name: blinkchamber
    app.kubernetes.io/instance: blinkchamber
    app.kubernetes.io/version: "1.0.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: prometheus
spec:
  selector:
    app.kubernetes.io/name: blinkchamber
    app.kubernetes.io/instance: blinkchamber
    app.kubernetes.io/component: prometheus
  ports:
  - name: http
    port: 9090
    targetPort: 9090
  type: ClusterIP
---
# Source: blinkchamber/templates/zitadel-deployment.yaml
apiVersion: v1
kind: Service
metadata:
  name: blinkchamber-zitadel
  namespace: blinkchamber
  labels:
    helm.sh/chart: blinkchamber-0.1.0
    app.kubernetes.io/name: blinkchamber
    app.kubernetes.io/instance: blinkchamber
    app.kubernetes.io/version: "1.0.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: zitadel
spec:
  selector:
    app.kubernetes.io/name: blinkchamber
    app.kubernetes.io/instance: blinkchamber
    app.kubernetes.io/component: zitadel
  ports:
  - name: http
    port: 8080
    targetPort: 8080
  type: ClusterIP
---
# Source: blinkchamber/charts/vault/templates/injector-deployment.yaml
# Deployment for the injector
apiVersion: apps/v1
kind: Deployment
metadata:
  name: blinkchamber-vault-agent-injector
  namespace: blinkchamber
  labels:
    app.kubernetes.io/name: vault-agent-injector
    app.kubernetes.io/instance: blinkchamber
    app.kubernetes.io/managed-by: Helm
    component: webhook
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: vault-agent-injector
      app.kubernetes.io/instance: blinkchamber
      component: webhook
  
  template:
    metadata:
      labels:
        app.kubernetes.io/name: vault-agent-injector
        app.kubernetes.io/instance: blinkchamber
        component: webhook
    spec:
      
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            - labelSelector:
                matchLabels:
                  app.kubernetes.io/name: vault-agent-injector
                  app.kubernetes.io/instance: "blinkchamber"
                  component: webhook
              topologyKey: kubernetes.io/hostname
  
      
      
      
      serviceAccountName: "blinkchamber-vault-agent-injector"
      
      securityContext:
        runAsNonRoot: true
        runAsGroup: 1000
        runAsUser: 100
        fsGroup: 1000
      hostNetwork: false
      containers:
        - name: sidecar-injector
          
          image: "hashicorp/vault-k8s:1.3.1"
          imagePullPolicy: "IfNotPresent"
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
                - ALL
          env:
            - name: AGENT_INJECT_LISTEN
              value: :8080
            - name: AGENT_INJECT_LOG_LEVEL
              value: info
            - name: AGENT_INJECT_VAULT_ADDR
              value: http://blinkchamber-vault.blinkchamber.svc:8200
            - name: AGENT_INJECT_VAULT_AUTH_PATH
              value: auth/kubernetes
            - name: AGENT_INJECT_VAULT_IMAGE
              value: "hashicorp/vault:1.15.2"
            - name: AGENT_INJECT_TLS_AUTO
              value: blinkchamber-vault-agent-injector-cfg
            - name: AGENT_INJECT_TLS_AUTO_HOSTS
              value: blinkchamber-vault-agent-injector-svc,blinkchamber-vault-agent-injector-svc.blinkchamber,blinkchamber-vault-agent-injector-svc.blinkchamber.svc
            - name: AGENT_INJECT_LOG_FORMAT
              value: standard
            - name: AGENT_INJECT_REVOKE_ON_SHUTDOWN
              value: "false"
            - name: AGENT_INJECT_CPU_REQUEST
              value: "250m"
            - name: AGENT_INJECT_CPU_LIMIT
              value: "500m"
            - name: AGENT_INJECT_MEM_REQUEST
              value: "64Mi"
            - name: AGENT_INJECT_MEM_LIMIT
              value: "128Mi"
            - name: AGENT_INJECT_DEFAULT_TEMPLATE
              value: "map"
            - name: AGENT_INJECT_TEMPLATE_CONFIG_EXIT_ON_RETRY_FAILURE
              value: "true"
            
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
          args:
            - agent-inject
            - 2>&1
          livenessProbe:
            httpGet:
              path: /health/ready
              port: 8080
              scheme: HTTPS
            failureThreshold: 2
            initialDelaySeconds: 5
            periodSeconds: 2
            successThreshold: 1
            timeoutSeconds: 5
          readinessProbe:
            httpGet:
              path: /health/ready
              port: 8080
              scheme: HTTPS
            failureThreshold: 2
            initialDelaySeconds: 5
            periodSeconds: 2
            successThreshold: 1
            timeoutSeconds: 5
          startupProbe:
            httpGet:
              path: /health/ready
              port: 8080
              scheme: HTTPS
            failureThreshold: 12
            initialDelaySeconds: 5
            periodSeconds: 5
            successThreshold: 1
            timeoutSeconds: 5
---
# Source: blinkchamber/templates/grafana-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: blinkchamber-grafana
  namespace: blinkchamber
  labels:
    helm.sh/chart: blinkchamber-0.1.0
    app.kubernetes.io/name: blinkchamber
    app.kubernetes.io/instance: blinkchamber
    app.kubernetes.io/version: "1.0.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: grafana
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: blinkchamber
      app.kubernetes.io/instance: blinkchamber
      app.kubernetes.io/component: grafana
  template:
    metadata:
      labels:
        app.kubernetes.io/name: blinkchamber
        app.kubernetes.io/instance: blinkchamber
        app.kubernetes.io/component: grafana
    spec:
      serviceAccountName: blinkchamber-grafana-sa
      initContainers:
        - name: wait-vault-secrets
          image: busybox:1.35
          command: ['sh', '-c', 'while [ ! -f /vault/secrets/grafana_admin_password ]; do echo "Waiting for Vault secrets..."; sleep 2; done; echo "Vault secrets ready"']
          volumeMounts:
            - name: vault-secrets
              mountPath: /vault/secrets
      containers:
        - name: grafana
          image: grafana/grafana:10.2.0
          ports:
            - containerPort: 3000
              name: http
          env:
            - name: GF_SECURITY_ADMIN_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: vault-secrets
                  key: grafana_admin_password
            - name: GF_SERVER_ROOT_URL
              value: "https://grafana.blinkchamber.local"
            - name: GF_SERVER_SERVE_FROM_SUB_PATH
              value: "false"
            - name: GF_INSTALL_PLUGINS
              value: "grafana-piechart-panel,grafana-worldmap-panel"
          volumeMounts:
            - name: grafana-storage
              mountPath: /var/lib/grafana
            - name: vault-secrets
              mountPath: /vault/secrets
              readOnly: true
          resources:
            limits:
              cpu: 500m
              memory: 512Mi
            requests:
              cpu: 100m
              memory: 128Mi
        - name: vault-agent
          image: hashicorp/vault:1.15.2
          args:
            - "agent"
            - "-config=/vault/config/agent-config.hcl"
          env:
            - name: VAULT_ADDR
              value: "http://blinkchamber-vault:8200"
          volumeMounts:
            - name: vault-secrets
              mountPath: /vault/secrets
            - name: vault-agent-config
              mountPath: /vault/config
          resources:
            requests:
              cpu: 50m
              memory: 64Mi
            limits:
              cpu: 200m
              memory: 128Mi
      volumes:
        - name: grafana-storage
          persistentVolumeClaim:
            claimName: blinkchamber-grafana-pvc
        - name: vault-secrets
          emptyDir:
            medium: Memory
        - name: vault-agent-config
          configMap:
            name: blinkchamber-grafana-vault-agent-config
---
# Source: blinkchamber/templates/mailu-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: blinkchamber-mailu
  namespace: blinkchamber
  labels:
    helm.sh/chart: blinkchamber-0.1.0
    app.kubernetes.io/name: blinkchamber
    app.kubernetes.io/instance: blinkchamber
    app.kubernetes.io/version: "1.0.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: mailu
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: blinkchamber
      app.kubernetes.io/instance: blinkchamber
      app.kubernetes.io/component: mailu
  template:
    metadata:
      labels:
        app.kubernetes.io/name: blinkchamber
        app.kubernetes.io/instance: blinkchamber
        app.kubernetes.io/component: mailu
    spec:
      serviceAccountName: blinkchamber-mailu-sa
      initContainers:
        - name: wait-vault-secrets
          image: busybox:1.35
          command:
            - 'sh'
            - '-c'
            - 'while [ ! -f /vault/secrets/mailu_secret_key ]; do echo "Waiting for Vault secrets..."; sleep 2; done; echo "Vault secrets ready"'
          volumeMounts:
            - name: vault-secrets
              mountPath: /vault/secrets
      containers:
        - name: mailu
          image: mailu/nginx:2.0
          ports:
            - containerPort: 80
              name: http
            - containerPort: 443
              name: https
            - containerPort: 25
              name: smtp
            - containerPort: 587
              name: smtps
            - containerPort: 143
              name: imap
            - containerPort: 993
              name: imaps
            - containerPort: 110
              name: pop3
            - containerPort: 995
              name: pop3s
          env:
            - name: MAILU_HOSTNAME
              value: "mail.blinkchamber.local"
            - name: MAILU_SECRET_KEY
              valueFrom:
                secretKeyRef:
                  name: vault-secrets
                  key: mailu_secret_key
            - name: MAILU_ADMIN_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: vault-secrets
                  key: mailu_admin_password
            - name: MAILU_DB_HOST
              value: "blinkchamber-postgresql"
            - name: MAILU_DB_PORT
              value: "5432"
            - name: MAILU_DB_NAME
              value: "mailu"
            - name: MAILU_DB_USER
              value: "mailu"
            - name: MAILU_DB_PASS
              valueFrom:
                secretKeyRef:
                  name: vault-secrets
                  key: mailu_db_password
          volumeMounts:
            - name: mailu-storage
              mountPath: /data
            - name: mailu-config
              mountPath: /etc/mailu
            - name: vault-secrets
              mountPath: /vault/secrets
              readOnly: true
          resources:
            limits:
              cpu: 1000m
              memory: 1Gi
            requests:
              cpu: 200m
              memory: 256Mi
        - name: vault-agent
          image: hashicorp/vault:1.15.2
          args:
            - "agent"
            - "-config=/vault/config/agent-config.hcl"
          env:
            - name: VAULT_ADDR
              value: "http://blinkchamber-vault:8200"
            - name: VAULT_CACERT
              value: "/vault/config/ca.crt"
          volumeMounts:
            - name: vault-secrets
              mountPath: /vault/secrets
            - name: vault-agent-config
              mountPath: /vault/config
          resources:
            requests:
              cpu: 50m
              memory: 64Mi
            limits:
              cpu: 200m
              memory: 128Mi
      volumes:
      - name: mailu-storage
        persistentVolumeClaim:
          claimName: blinkchamber-mailu-pvc
      - name: mailu-config
        configMap:
          name: blinkchamber-mailu-config
      - name: vault-secrets
        emptyDir:
          medium: Memory
      - name: vault-agent-config
        configMap:
          name: blinkchamber-mailu-vault-agent-config
---
# Source: blinkchamber/templates/prometheus-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: blinkchamber-prometheus
  namespace: blinkchamber
  labels:
    helm.sh/chart: blinkchamber-0.1.0
    app.kubernetes.io/name: blinkchamber
    app.kubernetes.io/instance: blinkchamber
    app.kubernetes.io/version: "1.0.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: prometheus
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: blinkchamber
      app.kubernetes.io/instance: blinkchamber
      app.kubernetes.io/component: prometheus
  template:
    metadata:
      labels:
        app.kubernetes.io/name: blinkchamber
        app.kubernetes.io/instance: blinkchamber
        app.kubernetes.io/component: prometheus
    spec:
      serviceAccountName: blinkchamber-prometheus-sa
      initContainers:
        - name: wait-vault-secrets
          image: busybox:1.35
          command:
            - 'sh'
            - '-c'
            - 'while [ ! -f /vault/secrets/prometheus_admin_password ]; do echo "Waiting for Vault secrets..."; sleep 2; done; echo "Vault secrets ready"'
          volumeMounts:
            - name: vault-secrets
              mountPath: /vault/secrets
      containers:
        - name: prometheus
          image: prom/prometheus:v2.47.0
          ports:
            - containerPort: 9090
              name: http
          args:
            - '--config.file=/etc/prometheus/prometheus.yml'
            - '--storage.tsdb.path=/prometheus'
            - '--web.console.libraries=/etc/prometheus/console_libraries'
            - '--web.console.templates=/etc/prometheus/consoles'
            - '--storage.tsdb.retention.time=200h'
            - '--web.enable-lifecycle'
          env:
            - name: PROMETHEUS_ADMIN_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: vault-secrets
                  key: prometheus_admin_password
          volumeMounts:
            - name: prometheus-config
              mountPath: /etc/prometheus
            - name: prometheus-storage
              mountPath: /prometheus
            - name: vault-secrets
              mountPath: /vault/secrets
              readOnly: true
          resources:
            limits:
              cpu: 500m
              memory: 512Mi
            requests:
              cpu: 100m
              memory: 128Mi
        - name: vault-agent
          image: hashicorp/vault:1.15.2
          args:
            - "agent"
            - "-config=/vault/config/agent-config.hcl"
          env:
            - name: VAULT_ADDR
              value: "http://blinkchamber-vault:8200"
          volumeMounts:
            - name: vault-secrets
              mountPath: /vault/secrets
            - name: vault-agent-config
              mountPath: /vault/config
          resources:
            requests:
              cpu: 50m
              memory: 64Mi
            limits:
              cpu: 200m
              memory: 128Mi
      volumes:
        - name: prometheus-config
          configMap:
            name: blinkchamber-prometheus-config
        - name: prometheus-storage
          persistentVolumeClaim:
            claimName: blinkchamber-prometheus-pvc
        - name: vault-secrets
          emptyDir:
            medium: Memory
        - name: vault-agent-config
          configMap:
            name: blinkchamber-prometheus-vault-agent-config
---
# Source: blinkchamber/templates/zitadel-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: blinkchamber-zitadel
  namespace: blinkchamber
  labels:
    helm.sh/chart: blinkchamber-0.1.0
    app.kubernetes.io/name: blinkchamber
    app.kubernetes.io/instance: blinkchamber
    app.kubernetes.io/version: "1.0.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: zitadel
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: blinkchamber
      app.kubernetes.io/instance: blinkchamber
      app.kubernetes.io/component: zitadel
  template:
    metadata:
      labels:
        app.kubernetes.io/name: blinkchamber
        app.kubernetes.io/instance: blinkchamber
        app.kubernetes.io/component: zitadel
    spec:
      serviceAccountName: blinkchamber-zitadel-sa
      initContainers:
        - name: wait-vault-secrets
          image: busybox:1.35
          command:
            - 'sh'
            - '-c'
            - 'while [ ! -f /vault/secrets/zitadel_masterkey ]; do echo "Waiting for Vault secrets..."; sleep 2; done; echo "Vault secrets ready"'
          volumeMounts:
            - name: vault-secrets
              mountPath: /vault/secrets
      containers:
        - name: zitadel
          image: ghcr.io/zitadel/zitadel:v2.42.0
          ports:
            - containerPort: 8080
              name: http
          env:
            - name: ZITADEL_MASTERKEY
              valueFrom:
                secretKeyRef:
                  name: vault-secrets
                  key: zitadel_masterkey
            - name: ZITADEL_ADMIN_USERNAME
              valueFrom:
                secretKeyRef:
                  name: vault-secrets
                  key: zitadel_admin_username
            - name: ZITADEL_ADMIN_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: vault-secrets
                  key: zitadel_admin_password
            - name: ZITADEL_DATABASE_POSTGRES_HOST
              value: "blinkchamber-postgresql"
            - name: ZITADEL_DATABASE_POSTGRES_PORT
              value: "5432"
            - name: ZITADEL_DATABASE_POSTGRES_DATABASE
              value: "zitadel"
            - name: ZITADEL_DATABASE_POSTGRES_USER_USERNAME
              valueFrom:
                secretKeyRef:
                  name: vault-secrets
                  key: postgres_username
            - name: ZITADEL_DATABASE_POSTGRES_USER_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: vault-secrets
                  key: postgres_password
            - name: ZITADEL_DATABASE_POSTGRES_ADMIN_USERNAME
              valueFrom:
                secretKeyRef:
                  name: vault-secrets
                  key: postgres_username
            - name: ZITADEL_DATABASE_POSTGRES_ADMIN_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: vault-secrets
                  key: postgres_password
            - name: ZITADEL_DATABASE_POSTGRES_USER_SSL_MODE
              value: "disable"
            - name: ZITADEL_DATABASE_POSTGRES_ADMIN_SSL_MODE
              value: "disable"
            - name: ZITADEL_SMTP_HOST
              value: "blinkchamber-mailu"
            - name: ZITADEL_SMTP_PORT
              value: "587"
            - name: ZITADEL_SMTP_USER
              value: "admin@blinkchamber.local"
            - name: ZITADEL_SMTP_PASSWORD
              value: "admin123"
            - name: ZITADEL_SMTP_FROM_ADDRESS
              value: "noreply@blinkchamber.local"
            - name: ZITADEL_SMTP_TLS
              value: "true"
            - name: ZITADEL_SMTP_STARTTLS
              value: "true"
            - name: ZITADEL_EXTERNALSECURE
              value: "false"
            - name: ZITADEL_TLS_ENABLED
              value: "false"
          volumeMounts:
            - name: vault-secrets
              mountPath: /vault/secrets
              readOnly: true
          command:
            - "/app/zitadel"
          args:
            - "start-from-init"
            - "--masterkey"
            - "$(cat /vault/secrets/zitadel_masterkey)"
            - "--tlsMode"
            - "disabled"
          livenessProbe:
            httpGet:
              path: /debug/healthz
              port: 8080
            initialDelaySeconds: 60
            periodSeconds: 30
          readinessProbe:
            httpGet:
              path: /debug/ready
              port: 8080
            initialDelaySeconds: 30
            periodSeconds: 10
          resources:
            limits:
              cpu: 1000m
              memory: 2Gi
            requests:
              cpu: 200m
              memory: 512Mi
        - name: vault-agent
          image: hashicorp/vault:1.15.2
          args:
            - "agent"
            - "-config=/vault/config/agent-config.hcl"
          env:
            - name: VAULT_ADDR
              value: "http://blinkchamber-vault:8200"
          volumeMounts:
            - name: vault-secrets
              mountPath: /vault/secrets
            - name: vault-agent-config
              mountPath: /vault/config
          resources:
            requests:
              cpu: 50m
              memory: 64Mi
            limits:
              cpu: 200m
              memory: 128Mi
      volumes:
        - name: vault-secrets
          emptyDir:
            medium: Memory
        - name: vault-agent-config
          configMap:
            name: blinkchamber-zitadel-vault-agent-config
---
# Source: blinkchamber/charts/postgresql/templates/primary/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: blinkchamber-postgresql
  namespace: "blinkchamber"
  labels:
    app.kubernetes.io/instance: blinkchamber
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/version: 16.1.0
    helm.sh/chart: postgresql-13.2.30
    app.kubernetes.io/component: primary
spec:
  replicas: 1
  serviceName: blinkchamber-postgresql-hl
  updateStrategy:
    rollingUpdate: {}
    type: RollingUpdate
  selector:
    matchLabels:
      app.kubernetes.io/instance: blinkchamber
      app.kubernetes.io/name: postgresql
      app.kubernetes.io/component: primary
  template:
    metadata:
      name: blinkchamber-postgresql
      labels:
        app.kubernetes.io/instance: blinkchamber
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: postgresql
        app.kubernetes.io/version: 16.1.0
        helm.sh/chart: postgresql-13.2.30
        app.kubernetes.io/component: primary
    spec:
      serviceAccountName: blinkchamber-postgresql
      
      affinity:
        podAffinity:
          
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/instance: blinkchamber
                    app.kubernetes.io/name: postgresql
                    app.kubernetes.io/component: primary
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:
          
      securityContext:
        fsGroup: 1001
      hostNetwork: false
      hostIPC: false
      containers:
        - name: postgresql
          image: docker.io/bitnami/postgresql:16.1.0-debian-11-r19
          imagePullPolicy: "IfNotPresent"
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            privileged: false
            readOnlyRootFilesystem: false
            runAsNonRoot: true
            runAsUser: 1001
            seccompProfile:
              type: RuntimeDefault
          env:
            - name: BITNAMI_DEBUG
              value: "false"
            - name: POSTGRESQL_PORT_NUMBER
              value: "5432"
            - name: POSTGRESQL_VOLUME_DIR
              value: "/bitnami/postgresql"
            - name: PGDATA
              value: "/bitnami/postgresql/data"
            # Authentication
            - name: POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: blinkchamber-postgresql
                  key: postgres-password
            - name: POSTGRES_DATABASE
              value: "zitadel"
            # Replication
            # Initdb
            # Standby
            # LDAP
            - name: POSTGRESQL_ENABLE_LDAP
              value: "no"
            # TLS
            - name: POSTGRESQL_ENABLE_TLS
              value: "no"
            # Audit
            - name: POSTGRESQL_LOG_HOSTNAME
              value: "false"
            - name: POSTGRESQL_LOG_CONNECTIONS
              value: "false"
            - name: POSTGRESQL_LOG_DISCONNECTIONS
              value: "false"
            - name: POSTGRESQL_PGAUDIT_LOG_CATALOG
              value: "off"
            # Others
            - name: POSTGRESQL_CLIENT_MIN_MESSAGES
              value: "error"
            - name: POSTGRESQL_SHARED_PRELOAD_LIBRARIES
              value: "pgaudit"
          ports:
            - name: tcp-postgresql
              containerPort: 5432
          livenessProbe:
            failureThreshold: 6
            initialDelaySeconds: 30
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
            exec:
              command:
                - /bin/sh
                - -c
                - exec pg_isready -U "postgres" -d "dbname=zitadel" -h 127.0.0.1 -p 5432
          readinessProbe:
            failureThreshold: 6
            initialDelaySeconds: 5
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
            exec:
              command:
                - /bin/sh
                - -c
                - -e
                - |
                  exec pg_isready -U "postgres" -d "dbname=zitadel" -h 127.0.0.1 -p 5432
                  [ -f /opt/bitnami/postgresql/tmp/.initialized ] || [ -f /bitnami/postgresql/.initialized ]
          resources:
            limits:
              cpu: 1000m
              memory: 1Gi
            requests:
              cpu: 200m
              memory: 256Mi
          volumeMounts:
            - name: dshm
              mountPath: /dev/shm
            - name: data
              mountPath: /bitnami/postgresql
      volumes:
        - name: dshm
          emptyDir:
            medium: Memory
  volumeClaimTemplates:
    - apiVersion: v1
      kind: PersistentVolumeClaim
      metadata:
        name: data
      spec:
        accessModes:
          - "ReadWriteOnce"
        resources:
          requests:
            storage: "10Gi"
        storageClassName: standard
---
# Source: blinkchamber/charts/vault/templates/server-statefulset.yaml
# StatefulSet to run the actual vault server cluster.
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: blinkchamber-vault
  namespace: blinkchamber
  labels:
    app.kubernetes.io/name: vault
    app.kubernetes.io/instance: blinkchamber
    app.kubernetes.io/managed-by: Helm
spec:
  serviceName: blinkchamber-vault-internal
  podManagementPolicy: Parallel
  replicas: 3
  updateStrategy:
    type: OnDelete
  selector:
    matchLabels:
      app.kubernetes.io/name: vault
      app.kubernetes.io/instance: blinkchamber
      component: server
  template:
    metadata:
      labels:
        helm.sh/chart: vault-0.27.0
        app.kubernetes.io/name: vault
        app.kubernetes.io/instance: blinkchamber
        component: server
    spec:
      
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            - labelSelector:
                matchLabels:
                  app.kubernetes.io/name: vault
                  app.kubernetes.io/instance: "blinkchamber"
                  component: server
              topologyKey: kubernetes.io/hostname
  
      
      
      
      terminationGracePeriodSeconds: 10
      serviceAccountName: blinkchamber-vault
      
      securityContext:
        runAsNonRoot: true
        runAsGroup: 1000
        runAsUser: 100
        fsGroup: 1000
      hostNetwork: false
      volumes:
        
        - name: config
          configMap:
            name: blinkchamber-vault-config
  
        - name: home
          emptyDir: {}
      containers:
        - name: vault
          resources:
            limits:
              cpu: 1000m
              memory: 1Gi
            requests:
              cpu: 200m
              memory: 256Mi
  
          image: hashicorp/vault:1.15.2
          imagePullPolicy: IfNotPresent
          command:
          - "/bin/sh"
          - "-ec"
          args: 
          - |
            cp /vault/config/extraconfig-from-values.hcl /tmp/storageconfig.hcl;
            [ -n "${HOST_IP}" ] && sed -Ei "s|HOST_IP|${HOST_IP?}|g" /tmp/storageconfig.hcl;
            [ -n "${POD_IP}" ] && sed -Ei "s|POD_IP|${POD_IP?}|g" /tmp/storageconfig.hcl;
            [ -n "${HOSTNAME}" ] && sed -Ei "s|HOSTNAME|${HOSTNAME?}|g" /tmp/storageconfig.hcl;
            [ -n "${API_ADDR}" ] && sed -Ei "s|API_ADDR|${API_ADDR?}|g" /tmp/storageconfig.hcl;
            [ -n "${TRANSIT_ADDR}" ] && sed -Ei "s|TRANSIT_ADDR|${TRANSIT_ADDR?}|g" /tmp/storageconfig.hcl;
            [ -n "${RAFT_ADDR}" ] && sed -Ei "s|RAFT_ADDR|${RAFT_ADDR?}|g" /tmp/storageconfig.hcl;
            /usr/local/bin/docker-entrypoint.sh vault server -config=/tmp/storageconfig.hcl 
   
          securityContext:
            allowPrivilegeEscalation: false
          env:
            - name: HOST_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.hostIP
            - name: POD_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.podIP
            - name: VAULT_K8S_POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: VAULT_K8S_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: VAULT_ADDR
              value: "http://127.0.0.1:8200"
            - name: VAULT_API_ADDR
              value: "http://$(POD_IP):8200"
            - name: SKIP_CHOWN
              value: "true"
            - name: SKIP_SETCAP
              value: "true"
            - name: HOSTNAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: VAULT_CLUSTER_ADDR
              value: "https://$(HOSTNAME).blinkchamber-vault-internal:8201"
            - name: HOME
              value: "/home/vault"
            
            
            
          volumeMounts:
          
  
  
            - name: config
              mountPath: /vault/config
  
            - name: home
              mountPath: /home/vault
          ports:
            - containerPort: 8200
              name: http
            - containerPort: 8201
              name: https-internal
            - containerPort: 8202
              name: http-rep
          readinessProbe:
            # Check status; unsealed vault servers return 0
            # The exit code reflects the seal status:
            #   0 - unsealed
            #   1 - error
            #   2 - sealed
            exec:
              command: ["/bin/sh", "-ec", "vault status -tls-skip-verify"]
            failureThreshold: 2
            initialDelaySeconds: 5
            periodSeconds: 5
            successThreshold: 1
            timeoutSeconds: 3
          lifecycle:
            # Vault container doesn't receive SIGTERM from Kubernetes
            # and after the grace period ends, Kube sends SIGKILL.  This
            # causes issues with graceful shutdowns such as deregistering itself
            # from Consul (zombie services).
            preStop:
              exec:
                command: [
                  "/bin/sh", "-c",
                  # Adding a sleep here to give the pod eviction a
                  # chance to propagate, so requests will not be made
                  # to this pod while it's terminating
                  "sleep 5 && kill -SIGTERM $(pidof vault)",
                ]
      
  
  volumeClaimTemplates:
---
# Source: blinkchamber/templates/grafana-deployment.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: blinkchamber-grafana
  namespace: blinkchamber
  labels:
    helm.sh/chart: blinkchamber-0.1.0
    app.kubernetes.io/name: blinkchamber
    app.kubernetes.io/instance: blinkchamber
    app.kubernetes.io/version: "1.0.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: grafana
  annotations:
    cert-manager.io/cluster-issuer: ca-issuer
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
spec:
  ingressClassName: nginx
  tls:
    - hosts:
      - "monitoring.blinkchamber.local"
      secretName: grafana-tls
  rules:
    - host: "monitoring.blinkchamber.local"
      http:
        paths:
          - path: /grafana
            pathType: Prefix
            backend:
              service:
                name: blinkchamber-grafana
                port:
                  number: 3000
---
# Source: blinkchamber/templates/mailu-deployment.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: blinkchamber-mailu
  namespace: blinkchamber
  labels:
    helm.sh/chart: blinkchamber-0.1.0
    app.kubernetes.io/name: blinkchamber
    app.kubernetes.io/instance: blinkchamber
    app.kubernetes.io/version: "1.0.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: mailu
  annotations:
    cert-manager.io/cluster-issuer: ca-issuer
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
spec:
  ingressClassName: nginx
  tls:
    - hosts:
      - "mail.blinkchamber.local"
      secretName: mailu-tls
  rules:
    - host: "mail.blinkchamber.local"
      http:
        paths:
          - path: /
            pathType: Prefix
            backend:
              service:
                name: blinkchamber-mailu
                port:
                  number: 80
---
# Source: blinkchamber/templates/prometheus-deployment.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: blinkchamber-prometheus
  namespace: blinkchamber
  labels:
    helm.sh/chart: blinkchamber-0.1.0
    app.kubernetes.io/name: blinkchamber
    app.kubernetes.io/instance: blinkchamber
    app.kubernetes.io/version: "1.0.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: prometheus
  annotations:
    cert-manager.io/cluster-issuer: ca-issuer
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
spec:
  ingressClassName: nginx
  tls:
    - hosts:
      - "monitoring.blinkchamber.local"
      secretName: prometheus-tls
  rules:
    - host: "monitoring.blinkchamber.local"
      http:
        paths:
          - path: /prometheus
            pathType: Prefix
            backend:
              service:
                name: blinkchamber-prometheus
                port:
                  number: 9090
---
# Source: blinkchamber/templates/zitadel-deployment.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: blinkchamber-zitadel
  namespace: blinkchamber
  labels:
    helm.sh/chart: blinkchamber-0.1.0
    app.kubernetes.io/name: blinkchamber
    app.kubernetes.io/instance: blinkchamber
    app.kubernetes.io/version: "1.0.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: zitadel
  annotations:
    cert-manager.io/cluster-issuer: ca-issuer
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
spec:
  ingressClassName: nginx
  tls:
    - hosts:
      - "identity.blinkchamber.local"
      secretName: zitadel-tls
  rules:
    - host: "identity.blinkchamber.local"
      http:
        paths:
          - path: /
            pathType: Prefix
            backend:
              service:
                name: blinkchamber-zitadel
                port:
                  number: 8080
---
# Source: blinkchamber/charts/vault/templates/injector-mutating-webhook.yaml
apiVersion: admissionregistration.k8s.io/v1
kind: MutatingWebhookConfiguration
metadata:
  name: blinkchamber-vault-agent-injector-cfg
  labels:
    app.kubernetes.io/name: vault-agent-injector
    app.kubernetes.io/instance: blinkchamber
    app.kubernetes.io/managed-by: Helm
webhooks:
  - name: vault.hashicorp.com
    failurePolicy: Ignore
    matchPolicy: Exact
    sideEffects: None
    timeoutSeconds: 30
    admissionReviewVersions: ["v1", "v1beta1"]
    clientConfig:
      service:
        name: blinkchamber-vault-agent-injector-svc
        namespace: blinkchamber
        path: "/mutate"
      caBundle: ""
    rules:
      - operations: ["CREATE", "UPDATE"]
        apiGroups: [""]
        apiVersions: ["v1"]
        resources: ["pods"]
    objectSelector:
      matchExpressions:
      - key: app.kubernetes.io/name
        operator: NotIn
        values:
        - vault-agent-injector
---
# Source: blinkchamber/charts/vault/templates/tests/server-test.yaml
apiVersion: v1
kind: Pod
metadata:
  name: blinkchamber-vault-server-test
  namespace: blinkchamber
  annotations:
    "helm.sh/hook": test
spec:
  
  containers:
    - name: blinkchamber-server-test
      image: hashicorp/vault:1.15.2
      imagePullPolicy: IfNotPresent
      env:
        - name: VAULT_ADDR
          value: http://blinkchamber-vault.blinkchamber.svc:8200
        
      command:
        - /bin/sh
        - -c
        - |
          echo "Checking for sealed info in 'vault status' output"
          ATTEMPTS=10
          n=0
          until [ "$n" -ge $ATTEMPTS ]
          do
            echo "Attempt" $n...
            vault status -format yaml | grep -E '^sealed: (true|false)' && break
            n=$((n+1))
            sleep 5
          done
          if [ $n -ge $ATTEMPTS ]; then
            echo "timed out looking for sealed info in 'vault status' output"
            exit 1
          fi

          exit 0
      volumeMounts:
  volumes:
  restartPolicy: Never
---
# Source: blinkchamber/templates/vault-init-job.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: blinkchamber-vault-init
  namespace: blinkchamber
  labels:
    helm.sh/chart: blinkchamber-0.1.0
    app.kubernetes.io/name: blinkchamber
    app.kubernetes.io/instance: blinkchamber
    app.kubernetes.io/version: "1.0.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: vault-init
  annotations:
    "helm.sh/hook": post-install,post-upgrade
    "helm.sh/hook-weight": "0"
    "helm.sh/hook-delete-policy": before-hook-creation,hook-succeeded
spec:
  template:
    metadata:
      labels:
        app.kubernetes.io/name: blinkchamber
        app.kubernetes.io/instance: blinkchamber
        app.kubernetes.io/component: vault-init
    spec:
      serviceAccountName: blinkchamber-vault-init
      restartPolicy: OnFailure
      containers:
      - name: vault-init
        image: bitnami/kubectl:latest
        command:
        - /bin/bash
        - -c
        - |
          set -e

          echo "🔍 Verificando estado de Vault..."

          # Esperar a que Vault esté listo
          kubectl wait --for=condition=ready pod -l app.kubernetes.io/name=vault -n blinkchamber --timeout=300s

          # Verificar si Vault ya está inicializado
          VAULT_STATUS=$(kubectl exec -n blinkchamber -l app.kubernetes.io/name=vault -- vault status -format=json 2>/dev/null || echo '{"initialized":false}')
          INITIALIZED=$(echo "$VAULT_STATUS" | jq -r '.initialized // false')

          if [[ "$INITIALIZED" == "true" ]]; then
            echo "✅ Vault ya está inicializado"
            exit 0
          fi

          echo "🚀 Inicializando Vault..."

          # Inicializar Vault
          INIT_RESPONSE=$(kubectl exec -n blinkchamber -l app.kubernetes.io/name=vault -- vault operator init -key-shares=5 -key-threshold=3 -format=json)

          # Extraer claves y token
          UNSEAL_KEYS=$(echo "$INIT_RESPONSE" | jq -r '.unseal_keys_b64[]' | tr '\n' ',' | sed 's/,$//')
          ROOT_TOKEN=$(echo "$INIT_RESPONSE" | jq -r '.root_token')

          echo "🔓 Desellando Vault..."

          # Desellar Vault con las primeras 3 claves
          IFS=',' read -ra KEYS <<< "$UNSEAL_KEYS"
          for i in {0..2}; do
            kubectl exec -n blinkchamber -l app.kubernetes.io/name=vault -- vault operator unseal "${KEYS[$i]}"
          done

          echo "🔧 Configurando Vault..."

          # Configurar autenticación de Kubernetes
          kubectl exec -n blinkchamber -l app.kubernetes.io/name=vault -- vault login "$ROOT_TOKEN"
          kubectl exec -n blinkchamber -l app.kubernetes.io/name=vault -- vault auth enable kubernetes

          # Configurar motor de secretos KV
          kubectl exec -n blinkchamber -l app.kubernetes.io/name=vault -- vault secrets enable -path=secret kv-v2

          # Crear secretos para todos los componentes (para Vault Agent Sidecar)
          echo "📝 Creando secretos para Vault Agent Sidecar..."

          kubectl exec -n blinkchamber -l app.kubernetes.io/name=vault -- vault kv put secret/database/postgres \
            username=postgres \
            password="$(openssl rand -base64 32)" \
            database=postgres

          kubectl exec -n blinkchamber -l app.kubernetes.io/name=vault -- vault kv put secret/identity/zitadel \
            admin_username=admin \
            admin_password="$(openssl rand -base64 16)" \
            masterkey="$(openssl rand -hex 32)"

          kubectl exec -n blinkchamber -l app.kubernetes.io/name=vault -- vault kv put secret/mail/mailu \
            secret_key="$(openssl rand -hex 32)" \
            admin_password="$(openssl rand -base64 16)" \
            database_password="$(openssl rand -base64 32)"

          kubectl exec -n blinkchamber -l app.kubernetes.io/name=vault -- vault kv put secret/monitoring/grafana \
            admin_username=admin \
            admin_password="$(openssl rand -base64 16)"

          kubectl exec -n blinkchamber -l app.kubernetes.io/name=vault -- vault kv put secret/monitoring/prometheus \
            admin_username=admin \
            admin_password="$(openssl rand -base64 16)"

          echo "🔐 Configurando roles y políticas para Vault Agent Sidecar..."

          # Configurar roles de Kubernetes para cada aplicación
          kubectl exec -n blinkchamber -l app.kubernetes.io/name=vault -- vault write auth/kubernetes/role/mailu-role \
            bound_service_account_names=mailu-sa \
            bound_service_account_namespaces=blinkchamber \
            policies=mailu-policy \
            ttl=1h

          kubectl exec -n blinkchamber -l app.kubernetes.io/name=vault -- vault write auth/kubernetes/role/grafana-role \
            bound_service_account_names=grafana-sa \
            bound_service_account_namespaces=blinkchamber \
            policies=grafana-policy \
            ttl=1h

          kubectl exec -n blinkchamber -l app.kubernetes.io/name=vault -- vault write auth/kubernetes/role/zitadel-role \
            bound_service_account_names=zitadel-sa \
            bound_service_account_namespaces=blinkchamber \
            policies=zitadel-policy \
            ttl=1h

          kubectl exec -n blinkchamber -l app.kubernetes.io/name=vault -- vault write auth/kubernetes/role/prometheus-role \
            bound_service_account_names=prometheus-sa \
            bound_service_account_namespaces=blinkchamber \
            policies=prometheus-policy \
            ttl=1h

          kubectl exec -n blinkchamber -l app.kubernetes.io/name=vault -- vault write auth/kubernetes/role/postgresql-role \
            bound_service_account_names=postgresql-sa \
            bound_service_account_namespaces=blinkchamber \
            policies=postgresql-policy \
            ttl=1h

          # Crear políticas específicas para cada aplicación
          kubectl exec -n blinkchamber -l app.kubernetes.io/name=vault -- vault policy write mailu-policy - <<EOF
          path "secret/data/mail/mailu" {
            capabilities = ["read"]
          }
          EOF

          kubectl exec -n blinkchamber -l app.kubernetes.io/name=vault -- vault policy write grafana-policy - <<EOF
          path "secret/data/monitoring/grafana" {
            capabilities = ["read"]
          }
          EOF

          kubectl exec -n blinkchamber -l app.kubernetes.io/name=vault -- vault policy write zitadel-policy - <<EOF
          path "secret/data/identity/zitadel" {
            capabilities = ["read"]
          }
          path "secret/data/database/postgres" {
            capabilities = ["read"]
          }
          EOF

          kubectl exec -n blinkchamber -l app.kubernetes.io/name=vault -- vault policy write prometheus-policy - <<EOF
          path "secret/data/monitoring/prometheus" {
            capabilities = ["read"]
          }
          EOF

          kubectl exec -n blinkchamber -l app.kubernetes.io/name=vault -- vault policy write postgresql-policy - <<EOF
          path "secret/data/database/postgres" {
            capabilities = ["read"]
          }
          EOF

          echo "✅ Vault inicializado y configurado exitosamente para Vault Agent Sidecar"

          # Guardar claves en secret (solo para desarrollo/backup)
          kubectl create secret generic blinkchamber-vault-keys \
            --from-literal=unseal-keys="$UNSEAL_KEYS" \
            --from-literal=root-token="$ROOT_TOKEN" \
            -n blinkchamber \
            --dry-run=client -o yaml | kubectl apply -f -

        env:
        - name: VAULT_ADDR
          value: "http://blinkchamber-vault:8200"
        resources:
          requests:
            cpu: 100m
            memory: 128Mi
          limits:
            cpu: 500m
            memory: 256Mi
